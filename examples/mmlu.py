#!/usr/bin/env python
# coding: utf-8

# get_ipython().system('curl -O https://people.eecs.berkeley.edu/~hendrycks/data.tar')
# get_ipython().system('tar -xf data.tar')
# data_path = "data"

import pandas as pd
import os
from utils import build_mmlu_data, build_env, get_registry_path

build_env()

registry_path = get_registry_path()

data_path = r'F:\nlpdata_2023\openai\evals\data'

# 构建数据
build_mmlu_data(data_path,registry_path)

# 评估
os.system('sh_aigc_evals langchain/chat_model/chatglm2-6b-int4 match_mmlu_electrical_engineering --registry_path="E:\\algo_project_2023\\aigc_evals\\registry"')


# # How to process the log events generated by oaieval
# events = "/tmp/evallogs/{log_name}"
#
# with open(events, "r") as f:
#     events_df = pd.read_json(f, lines=True)
#
# matches_df = events_df[events_df.type == "match"].reset_index(drop=True)
# matches_df = matches_df.join(pd.json_normalize(matches_df.data))
# matches_df.correct.value_counts().plot.bar(title="Correctness of generated answers", xlabel="Correctness", ylabel="Count")
#
#
# # In[ ]:
#
#
# # Inspect samples
# for i, r in pd.json_normalize(events_df[events_df.type == "sampling"].data).iterrows():
#     print(f"Prompt: {r.prompt}")
#     print(f"Sampled: {r.sampled}")
#     print("-" * 25)

